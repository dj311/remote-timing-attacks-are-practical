{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remote Timing Attacks are Practical\n",
    "_Experiment 6: Attacking SSL applications on the local network._\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import scipy.signal\n",
    "import seaborn\n",
    "import sympy\n",
    "import pandas\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython import display\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tls\n",
    "import attack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attack Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = sympy.Integer(11693128827090800677443535237632476895247105886644942164014088484470194179491435241190389270827811769965853291192455791684691555403909415703633832493911789)\n",
    "q = sympy.Integer(11353860437120204348539420361367294927683441924641720282978666316144621735920188475867378638813811676070362003602263559496393696538309271007870774914687283)\n",
    "N = sympy.Integer(132762152776056020551326919245624484615462467876809681535549565118332290525598572815747323476102181376625279228965473106140757139049665124368186142774966643990206422037551427526013151129106319233128471783533673959766053786798472937188481868923726256436384468384858420931063093337134977283618537887974322079287)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Analysis\n",
    "The aim of this notebook is to sample the server response times for a bunch of `g` values, and find out if the distribution is meaningfully different between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEIGHBOURHOOD_SIZE = 800\n",
    "SAMPLE_SIZE = 20\n",
    "BRUTEFORCED_BITS = 5\n",
    "\n",
    "filename = \"./measurements/bruteforce-top-bits.txt\"\n",
    "if not os.path.exists(filename):\n",
    "    gs = attack.bruteforce_most_significant_bits(num_bits=BRUTEFORCED_BITS)\n",
    "    \n",
    "    print(\"Taking {} samples...\".format(len(gs)*SAMPLE_SIZE*NEIGHBOURHOOD_SIZE))\n",
    "    \n",
    "    raw_samples = attack.sample(\n",
    "        gs,\n",
    "        sample_size=SAMPLE_SIZE,\n",
    "        neighbourhood_size=NEIGHBOURHOOD_SIZE,\n",
    "        u_g=True,\n",
    "        N=N,\n",
    "    )\n",
    "    samples = pandas.DataFrame.from_records(\n",
    "        raw_samples,\n",
    "        columns=[\"point\", \"time\"],\n",
    "    )\n",
    "    samples.to_csv(filename, sep=\" \")\n",
    "\n",
    "else:\n",
    "    samples = pandas.read_csv(\n",
    "        filename,\n",
    "        sep=\" \",\n",
    "        usecols=[\"point\", \"time\"],\n",
    "    )\n",
    "\n",
    "samples['point'] = samples['point'].apply(sympy.Integer)\n",
    "samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the paper, they take median time for each point. By taking the minimum, I hope to extract the fastest time possible, which should be the time with minimal context switches and other delays. This works provided the only sources of unwanted noise _add time_ (rather than remove it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "samples = samples.groupby(by=\"point\").median().reset_index()\n",
    "samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can group samples into their respective \"neighbourhoods\" considering their most significant bits only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_to_neighbourhood(point):\n",
    "    point_int = sympy.Integer(point)\n",
    "    point_bits = attack.sympy_integer_to_bits(point_int)\n",
    "    neighbourhood_point_bits = point_bits[0:BRUTEFORCED_BITS] + [0] * (512-BRUTEFORCED_BITS)\n",
    "    neighbourhood_point_int = attack.bits_to_sympy_integer(neighbourhood_point_bits)\n",
    "    return neighbourhood_point_int\n",
    "\n",
    "samples['neighbourhood'] = samples['point'].apply(point_to_neighbourhood)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sum together the measurements in each neighbourhood:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = samples.groupby(by=\"neighbourhood\").mean().reset_index()\n",
    "samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we know the factors of `N` (`q` and `p` with `q<p`) we can consider each point relative in size to these factors. When plotting, we are looking for peaks and troughs near whole multples of `p` and `q`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqrt_N = sympy.sqrt(N)\n",
    "samples['point_relative_to_sqrt_n'] = samples['neighbourhood'].apply(lambda g: round(float(g/sqrt_N), 10))\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_relative_to_sqrt_n = round(float(q/sqrt_N), 10)\n",
    "p_relative_to_sqrt_n = round(float(p/sqrt_N), 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now plot the media response time as we vary `g`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smallest_time_observed = samples['time'].min()\n",
    "largest_time_observed = samples['time'].max()\n",
    "\n",
    "buffer = (largest_time_observed - smallest_time_observed)/10\n",
    "\n",
    "smallest_time_observed, largest_time_observed, buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAMPLE_SIZE == 20 and NEIGHBOURHOOD_SIZE == 800:\n",
    "    error = 27442/2\n",
    "elif SAMPLE_SIZE == 7 and NEIGHBOURHOOD_SIZE == 400:\n",
    "    error = 42987/2\n",
    "else:\n",
    "    error = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = seaborn.relplot(data=samples, x='point_relative_to_sqrt_n', y='time', kind='line', height=8, aspect=16/8, marker=\"X\")\n",
    "if error:\n",
    "    plt.plot(samples['point_relative_to_sqrt_n'], [y + error for y in samples['time']], color='lightblue')\n",
    "    plt.plot(samples['point_relative_to_sqrt_n'], [y - error for y in samples['time']], color='lightblue')\n",
    "g.set(ylim=(smallest_time_observed-error-buffer, largest_time_observed+error+buffer))\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = seaborn.relplot(data=samples, x='point_relative_to_sqrt_n', y='time', kind='line', height=8, aspect=16/8, marker=\"X\")\n",
    "plt.plot([q_relative_to_sqrt_n, q_relative_to_sqrt_n], [smallest_time_observed*0.9, largest_time_observed*1.1], color='green')\n",
    "plt.plot([p_relative_to_sqrt_n, p_relative_to_sqrt_n], [smallest_time_observed*0.9, largest_time_observed*1.1], color='purple')\n",
    "if error:\n",
    "    plt.plot(samples['point_relative_to_sqrt_n'], [y + error for y in samples['time']], color='lightblue')\n",
    "    plt.plot(samples['point_relative_to_sqrt_n'], [y - error for y in samples['time']], color='lightblue')\n",
    "g.set(ylim=(smallest_time_observed-error-buffer, largest_time_observed+error+buffer))\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = seaborn.relplot(data=samples, x='point_relative_to_sqrt_n', y='time', kind='line', height=8, aspect=16/8, marker=\"X\")\n",
    "plt.plot([q_relative_to_sqrt_n, q_relative_to_sqrt_n], [smallest_time_observed*0.9, largest_time_observed*1.1], color='green')\n",
    "plt.plot([p_relative_to_sqrt_n, p_relative_to_sqrt_n], [smallest_time_observed*0.9, largest_time_observed*1.1], color='purple')\n",
    "if error:\n",
    "    plt.plot(samples['point_relative_to_sqrt_n'], [y + error for y in samples['time']], color='lightblue')\n",
    "    plt.plot(samples['point_relative_to_sqrt_n'], [y - error for y in samples['time']], color='lightblue')\n",
    "g.set(ylim=(smallest_time_observed-error-buffer, largest_time_observed+error+buffer))\n",
    "g.set(xlim=(q_relative_to_sqrt_n*0.9, p_relative_to_sqrt_n*1.1))\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the section below, we bound the value of $q$ using the shape of this graph. But its worth noting that the peaks and troughs in the graphs above fit well inside the error bars (calculated in the `noise.ipynb` notebook). It is likely this graph should just be a straight line. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bounding our search for `q`\n",
    "\n",
    "`scipy` finds two peaks in the sample set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_indices, _ = scipy.signal.find_peaks(samples['time'])\n",
    "len(peak_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets re-plot the above graph with the peaks highlighted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = seaborn.relplot(data=samples, x='point_relative_to_sqrt_n', y='time', kind='line', height=8, aspect=16/8, marker=\"X\")\n",
    "\n",
    "for peak_index in peak_indices:\n",
    "    peak = samples.iloc[peak_index]\n",
    "    plt.plot([peak['point_relative_to_sqrt_n'], peak['point_relative_to_sqrt_n']], [smallest_time_observed-error-buffer, largest_time_observed+error+buffer], color='orange')\n",
    "\n",
    "if error:\n",
    "    plt.plot(samples['point_relative_to_sqrt_n'], [y + error for y in samples['time']], color='lightblue')\n",
    "    plt.plot(samples['point_relative_to_sqrt_n'], [y - error for y in samples['time']], color='lightblue')\n",
    "g.set(ylim=(smallest_time_observed-error-buffer, largest_time_observed+error+buffer))\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to cheat a little and say that the first peak they've detected isn't quite a peak. We could have modified the `find_peaks` call to be more discerning, or fit a KDE to it, but I think its relatively clear the primary peak is the second value they've detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_index = 1\n",
    "peak_row = samples.iloc[peak_indices[1]]\n",
    "peak_g = peak_row['neighbourhood']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack.sympy_integer_to_bits(peak_g)[0:BRUTEFORCED_BITS]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives a lower bound on `q`. To get an upper bound on `q`, note the following:\n",
    "  1. $q*p = N$\n",
    "  2. $q < p$\n",
    "\n",
    "From 1. and 2. it follows that $q < \\sqrt{N}$.\n",
    "\n",
    "(Suppose $q >= \\sqrt{N}$, then by 2. $p > \\sqrt{N}$ and so $ q*p > N$ which contradicts 1. Therefore $q < \\sqrt{N}$.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_bound = peak_g\n",
    "upper_bound = sympy.Integer(sqrt_N.round())\n",
    "\n",
    "lower_bound, upper_bound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot these two bounds on the graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_bound_relative_to_sqrt_n = round(float(lower_bound/sqrt_N), 10)\n",
    "upper_bound_relative_to_sqrt_n = round(float(upper_bound/sqrt_N), 10)\n",
    "\n",
    "g = seaborn.relplot(data=samples, x='point_relative_to_sqrt_n', y='time', kind='line', height=8, aspect=16/8, marker=\"X\")\n",
    "\n",
    "plt.plot([lower_bound_relative_to_sqrt_n, lower_bound_relative_to_sqrt_n], [smallest_time_observed-error-buffer, largest_time_observed+error+buffer], color='orange')\n",
    "plt.plot([upper_bound_relative_to_sqrt_n, upper_bound_relative_to_sqrt_n], [smallest_time_observed-error-buffer, largest_time_observed+error+buffer], color='orange')\n",
    "\n",
    "if error:\n",
    "    plt.plot(samples['point_relative_to_sqrt_n'], [y + error for y in samples['time']], color='lightblue')\n",
    "    plt.plot(samples['point_relative_to_sqrt_n'], [y - error for y in samples['time']], color='lightblue')\n",
    "g.set(ylim=(smallest_time_observed-error-buffer, largest_time_observed+error+buffer))\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets consider the bit representations of these two bounds so we can set in stone the first few bits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Lower Bound:\", attack.sympy_integer_to_bits(lower_bound)[0:BRUTEFORCED_BITS])\n",
    "print(\"Upper Bound:\", attack.sympy_integer_to_bits(upper_bound)[0:BRUTEFORCED_BITS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_bound_bits = attack.sympy_integer_to_bits(lower_bound)\n",
    "upper_bound_bits = attack.sympy_integer_to_bits(upper_bound)\n",
    "\n",
    "known_q_bits = []\n",
    "for i in range(BRUTEFORCED_BITS):\n",
    "    if lower_bound_bits[i] == upper_bound_bits[i]:\n",
    "        known_q_bits.append(lower_bound_bits[i])\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "known_q_bits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above giving us the first bits of $q$.\n",
    "\n",
    "Since it is prime, we also know that $q$ is odd, and so its least significant bit is 1. We'll ignore that for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recovering Bits of $q$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the iterative key recovery attack on bits 1, 2, and 3. We already know their true values, so there zero-one gaps can be used as reference points for the other bits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BITS_TO_RECOVER = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_bits = attack.sympy_integer_to_bits(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bit_samples_filename = \"./measurements/bit-samples.txt\"\n",
    "bit_samples = pandas.DataFrame({\n",
    "    'bit_position': [],\n",
    "    'bit_value': [],\n",
    "    'point': [],\n",
    "    'time': [],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bits = []\n",
    "for i in range(0, 4):\n",
    "    g_low_samples, g_high_samples = attack.sample_ith_bit(\n",
    "        q_bits,\n",
    "        i,\n",
    "        sample_size=SAMPLE_SIZE,\n",
    "        neighbourhood_size=NEIGHBOURHOOD_SIZE,\n",
    "    )\n",
    "        \n",
    "    g_low_samples['bit_position'] = i\n",
    "    g_low_samples['bit_value'] = 0\n",
    "    \n",
    "    g_high_samples['bit_position'] = i\n",
    "    g_high_samples['bit_value'] = 1\n",
    "    \n",
    "    bit_samples = pandas.concat([bit_samples, g_low_samples, g_high_samples], axis=0, sort=True)\n",
    "    \n",
    "bit_samples.to_csv(bit_samples_filename, sep=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @DAN: Plot the distributions like I did with the bruteforcing back in the day?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a reasonable midpoint which could be used to separate the zeroes from the ones above. So lets continue and see what we get. Note that from here onwards, I've used the _correct_ bits of q, not the one the algorithm has picked, so there is a little cheating going on in the below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4, BITS_TO_RECOVER):\n",
    "    g_low_samples, g_high_samples = attack.sample_ith_bit(\n",
    "        q_bits,\n",
    "        i,\n",
    "        sample_size=SAMPLE_SIZE,\n",
    "        neighbourhood_size=NEIGHBOURHOOD_SIZE,\n",
    "    )\n",
    "        \n",
    "    g_low_samples['bit_position'] = i\n",
    "    g_low_samples['bit_value'] = 0\n",
    "    \n",
    "    g_high_samples['bit_position'] = i\n",
    "    g_high_samples['bit_value'] = 1\n",
    "    \n",
    "    bit_samples = pandas.concat([bit_samples, g_low_samples, g_high_samples], axis=0, sort=True)\n",
    "    \n",
    "    if i%5 == 0:\n",
    "        bit_samples.to_csv(bit_samples_filename, sep=\" \")\n",
    "\n",
    "bit_samples.to_csv(bit_samples_filename, sep=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot them so we can contrast their distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zero_one_gaps = pandas.DataFrame({\n",
    "#     'True Value': q_bits[1:BITS_TO_RECOVER],\n",
    "#     'Zero-One Gap': gaps,\n",
    "#     'Bit': range(1, BITS_TO_RECOVER),\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seaborn.relplot(\n",
    "#     data=zero_one_gaps,\n",
    "#     x='Bit',\n",
    "#     y='Zero-One Gap',\n",
    "#     hue='True Value',\n",
    "#     kind='scatter',\n",
    "#     height=8,\n",
    "#     aspect=16/8,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No midpoint exists which allows us to separate the two groups perfectly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coppersmiths Attack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "  - [1] https://crypto.stanford.edu/~dabo/papers/ssl-timing.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
